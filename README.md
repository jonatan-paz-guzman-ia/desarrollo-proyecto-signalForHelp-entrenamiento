# ğŸ§  Proyecto: Signal For Help - Entrenamiento de modelo YOLOv8

Este proyecto entrena un modelo de segmentaciÃ³n con YOLOv8 para identificar gestos de ayuda (palma abierta y puÃ±o cerrado), como parte de una soluciÃ³n de visiÃ³n computacional en contextos de emergencia.

## âš™ï¸ Requisitos

- Python 3.11
- [uv](https://github.com/astral-sh/uv) (gestor de entornos recomendado)
- Git
- ffmpeg, libgl1 (solo para entorno Docker o sistemas Linux)

## ğŸ”§ InstalaciÃ³n

```bash
uv venv
uv pip install -r requirements.txt

```
## ğŸš€ Entrenamiento del modelo

```bash
uv run src/train.py --data data/dataset.yaml --epochs 50 --img 640
```

## ğŸ“¸ Inferencia por imagen

```bash
uv run src/inference.py --source data/test/images
```

## ğŸ¥ Inferencia con cÃ¡mara en vivo

```bash
uv run src/inference_camera.py
```

## ğŸ§ª Pruebas unitarias

```bash
uv run pytest tests/
```

Incluye:
    - Carga del modelo
    - EjecuciÃ³n de inferencia
    - ValidaciÃ³n de resultados

## ğŸ³ Docker (opcional)

```bash
docker build -t signalforhelp-inference .
docker run --rm signalforhelp-inference
```
## ğŸ“ Estructura del proyecto

```bash
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â””â”€â”€ inference_camera.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_inference.py
â”œâ”€â”€ artefactos/
â”‚   â””â”€â”€ best.pt
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset.yaml
â”‚   â””â”€â”€ test/train/valid/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
```
## ğŸ‘¤ Autores

Jonatan Paz Guzman
GitHub: @jonatan-paz-guzman-ia

Dayana MuÃ±oz MuÃ±oz
GitHub: @dayana-IA

Daniel Carlosama MartÃ­nez
GitHub: @21danka